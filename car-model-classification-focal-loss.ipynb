{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "car_model_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF0XlGzywnqg",
        "outputId": "01a19f19-db04-402b-f532-9ae0925aef1e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNqPcmmFwbqT"
      },
      "source": [
        "# import the libraries as shown below\n",
        "\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "#from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZWhqvcnwbqU"
      },
      "source": [
        "# re-size all the images to this\n",
        "IMAGE_SIZE = [224, 224]\n",
        "\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/Train'\n",
        "valid_path = '/content/drive/MyDrive/Colab Notebooks/Dataset/Test'\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yIJL41TwbqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "461f89de-7e62-4041-fc0d-683f7d91fdf6"
      },
      "source": [
        "# Import the Resnet50 library as shown below and add preprocessing layer to the front of Resnet 50\n",
        "# Here we will be using imagenet weights\n",
        "\n",
        "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO-sLsFtzWMU",
        "outputId": "75cbe185-d49b-43cf-de16-dc28388f52bd"
      },
      "source": [
        "resnet.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vkbolGkwbqV"
      },
      "source": [
        "# don't train existing weights\n",
        "for layer in resnet.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4IrLuM6wbqV"
      },
      "source": [
        "  # useful for getting number of output classes\n",
        "import os\n",
        "folders = os.listdir('/content/drive/MyDrive/Colab Notebooks/Dataset/Train')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cK2U-9nETIuC",
        "outputId": "0d7e40eb-8970-4a24-e76d-884357e4f495"
      },
      "source": [
        "folders.sort()\n",
        "folders"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mahindra Marazzo',\n",
              " 'Maruti Ciaz',\n",
              " 'Maruti Ertiga',\n",
              " 'Tata Tigor',\n",
              " 'audi a4',\n",
              " 'bmw 320',\n",
              " 'chevrolet Uva Sail',\n",
              " 'chevrolet tavera',\n",
              " 'force',\n",
              " 'ford ecosport',\n",
              " 'ford fiesta',\n",
              " 'ford figo',\n",
              " 'honda amaze',\n",
              " 'honda brv',\n",
              " 'honda city',\n",
              " 'honda city zx',\n",
              " 'honda civic',\n",
              " 'honda jazz',\n",
              " 'honda mobilio',\n",
              " 'honda wrv',\n",
              " 'hyundai ACCENT',\n",
              " 'hyundai creta',\n",
              " 'hyundai eon',\n",
              " 'hyundai i10',\n",
              " 'hyundai i20',\n",
              " 'hyundai santro',\n",
              " 'hyundai verna',\n",
              " 'hyundai xcent',\n",
              " 'kia Carnival',\n",
              " 'mahindra bolero',\n",
              " 'mahindra imperio',\n",
              " 'mahindra scorpio',\n",
              " 'mahindra tuv300',\n",
              " 'mahindra xuv500',\n",
              " 'maruti 800',\n",
              " 'maruti Celario',\n",
              " 'maruti alto',\n",
              " 'maruti baleno',\n",
              " 'maruti brezza',\n",
              " 'maruti eeco',\n",
              " 'maruti ignis',\n",
              " 'maruti omni',\n",
              " 'maruti ritz',\n",
              " 'maruti scross',\n",
              " 'maruti swift',\n",
              " 'maruti swift dzire',\n",
              " 'maruti wagon r',\n",
              " 'maruti xl6',\n",
              " 'maruti xx4',\n",
              " 'maruti zen',\n",
              " 'maruti zen estilo',\n",
              " 'nissan kicks',\n",
              " 'nissan terrano',\n",
              " 'renault duster',\n",
              " 'renault kwid',\n",
              " 'skoda rapid',\n",
              " 'tata hexa',\n",
              " 'tata indigo',\n",
              " 'tata neno',\n",
              " 'tata nexon',\n",
              " 'tata safari',\n",
              " 'tata tiago',\n",
              " 'tata zest',\n",
              " 'toyota altis',\n",
              " 'toyota etios',\n",
              " 'toyota etios liva',\n",
              " 'toyota fortuner',\n",
              " 'toyota innova',\n",
              " 'volkswagen ameo',\n",
              " 'volkswagen polo',\n",
              " 'volvo xc40']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWgs6KfT0KOk",
        "outputId": "f939b4cb-cac5-4227-8fe9-81a739943996"
      },
      "source": [
        "# Number of output classes\n",
        "len(folders)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KGZXVuz2do6"
      },
      "source": [
        "### Distribution of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1zkLPwk2goe"
      },
      "source": [
        "class_dict = {}\n",
        "count = 0\n",
        "for i in glob('/content/drive/MyDrive/Colab Notebooks/Dataset/Train/*'):\n",
        "  class_dict[count]=len(glob(i+\"/*\"))\n",
        "  count+=1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_b0cX4L3c24",
        "outputId": "d161fbaf-2c3f-46e2-ac27-f2e69e09f79c"
      },
      "source": [
        "print(class_dict)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 2, 1: 1, 2: 1, 3: 6, 4: 7, 5: 8, 6: 1, 7: 5, 8: 9, 9: 1, 10: 3, 11: 1, 12: 14, 13: 39, 14: 1, 15: 4, 16: 1, 17: 8, 18: 14, 19: 16, 20: 25, 21: 43, 22: 56, 23: 9, 24: 65, 25: 160, 26: 39, 27: 3, 28: 1, 29: 3, 30: 6, 31: 1, 32: 5, 33: 12, 34: 100, 35: 1, 36: 19, 37: 6, 38: 25, 39: 3, 40: 6, 41: 1, 42: 22, 43: 6, 44: 1, 45: 1, 46: 9, 47: 1, 48: 33, 49: 26, 50: 27, 51: 13, 52: 6, 53: 5, 54: 1, 55: 1, 56: 125, 57: 12, 58: 11, 59: 5, 60: 1, 61: 1, 62: 23, 63: 2, 64: 56, 65: 2, 66: 22, 67: 2, 68: 3, 69: 14, 70: 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "qiUSq6-k3nrs",
        "outputId": "c32e09fb-d9a1-4d09-c58d-19c99bd1c091"
      },
      "source": [
        "\n",
        "from matplotlib.pyplot import figure\n",
        "figure(num=None, figsize=(20, 15), dpi=80, facecolor='w', edgecolor='k')\n",
        "plt.bar(list(class_dict.keys()), list(class_dict.values()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 71 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1600x1200 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM2g6KJhwbqV"
      },
      "source": [
        "# our layers - you can add more if you want\n",
        "x = Flatten()(resnet.output)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8uahLcnwbqW"
      },
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=resnet.input, outputs=prediction)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ua1ahn-wbqW",
        "outputId": "9e26aabc-80da-4a0f-8381-9b0fc773113f"
      },
      "source": [
        "\n",
        "# view the structure of the model\n",
        "model.summary()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 71)           7125063     flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 30,712,775\n",
            "Trainable params: 7,125,063\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXS4AxF9z_iN",
        "outputId": "0d358a6c-29b4-4ca4-9c9a-d2e4e31d6326"
      },
      "source": [
        "pip install focal-loss"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting focal-loss\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/96/babb0f40b2046a45aa2263773d915a34f02d4fb6bae91a505ce2db8ab0b2/focal_loss-0.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.6/dist-packages (from focal-loss) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (1.32.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (3.7.4.3)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (0.2.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (1.6.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (0.36.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (2.4.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (2.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.2->focal-loss) (2.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.2->focal-loss) (53.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (0.4.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.24.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.3.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (4.7)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (2020.12.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal-loss) (3.4.0)\n",
            "Installing collected packages: focal-loss\n",
            "Successfully installed focal-loss-0.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBodQ3YT4uoU",
        "outputId": "1a1d7223-ba7f-48c6-bf27-528f89466ec5"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjaqqrpEgI2-"
      },
      "source": [
        "def focal_loss(gamma=2., alpha=4.):\n",
        "\n",
        "    gamma = float(gamma)\n",
        "    alpha = float(alpha)\n",
        "\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"Focal loss for multi-classification\n",
        "        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n",
        "        Notice: y_pred is probability after softmax\n",
        "        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n",
        "        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n",
        "        Focal Loss for Dense Object Detection\n",
        "        https://arxiv.org/abs/1708.02002\n",
        "\n",
        "        Arguments:\n",
        "            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n",
        "            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n",
        "\n",
        "        Keyword Arguments:\n",
        "            gamma {float} -- (default: {2.0})\n",
        "            alpha {float} -- (default: {4.0})\n",
        "\n",
        "        Returns:\n",
        "            [tensor] -- loss.\n",
        "        \"\"\"\n",
        "        epsilon = 1.e-9\n",
        "        y_true = tf.convert_to_tensor(y_true, tf.float32)\n",
        "        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n",
        "\n",
        "        model_out = tf.add(y_pred, epsilon)\n",
        "        ce = tf.multiply(y_true, -tf.math.log(model_out))\n",
        "        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n",
        "        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n",
        "        reduced_fl = tf.reduce_max(fl, axis=1)\n",
        "        return tf.reduce_mean(reduced_fl)\n",
        "    return focal_loss_fixed"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvnKXlDawbqW"
      },
      "source": [
        "# tell the model what cost and optimization method to use\n",
        "model.compile(\n",
        "  loss=focal_loss(alpha=1),\n",
        "  optimizer='adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aOu0j1uwbqX"
      },
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBH9i2SKwbqX",
        "outputId": "a7fee6ea-3557-4212-8ad8-4b65d306d7e6"
      },
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Dataset/Train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1164 images belonging to 71 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ_YeXf-f0Ke",
        "outputId": "4fd58870-4d2a-4455-caaf-207817dc360c"
      },
      "source": [
        "dic_train = training_set.class_indices\n",
        "dic_train"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Mahindra Marazzo': 0,\n",
              " 'Maruti Ciaz': 1,\n",
              " 'Maruti Ertiga': 2,\n",
              " 'Tata Tigor': 3,\n",
              " 'audi a4': 4,\n",
              " 'bmw 320': 5,\n",
              " 'chevrolet Uva Sail': 6,\n",
              " 'chevrolet tavera': 7,\n",
              " 'force': 8,\n",
              " 'ford ecosport': 9,\n",
              " 'ford fiesta': 10,\n",
              " 'ford figo': 11,\n",
              " 'honda amaze': 12,\n",
              " 'honda brv': 13,\n",
              " 'honda city': 14,\n",
              " 'honda city zx': 15,\n",
              " 'honda civic': 16,\n",
              " 'honda jazz': 17,\n",
              " 'honda mobilio': 18,\n",
              " 'honda wrv': 19,\n",
              " 'hyundai ACCENT': 20,\n",
              " 'hyundai creta': 21,\n",
              " 'hyundai eon': 22,\n",
              " 'hyundai i10': 23,\n",
              " 'hyundai i20': 24,\n",
              " 'hyundai santro': 25,\n",
              " 'hyundai verna': 26,\n",
              " 'hyundai xcent': 27,\n",
              " 'kia Carnival': 28,\n",
              " 'mahindra bolero': 29,\n",
              " 'mahindra imperio': 30,\n",
              " 'mahindra scorpio': 31,\n",
              " 'mahindra tuv300': 32,\n",
              " 'mahindra xuv500': 33,\n",
              " 'maruti 800': 34,\n",
              " 'maruti Celario': 35,\n",
              " 'maruti alto': 36,\n",
              " 'maruti baleno': 37,\n",
              " 'maruti brezza': 38,\n",
              " 'maruti eeco': 39,\n",
              " 'maruti ignis': 40,\n",
              " 'maruti omni': 41,\n",
              " 'maruti ritz': 42,\n",
              " 'maruti scross': 43,\n",
              " 'maruti swift': 44,\n",
              " 'maruti swift dzire': 45,\n",
              " 'maruti wagon r': 46,\n",
              " 'maruti xl6': 47,\n",
              " 'maruti xx4': 48,\n",
              " 'maruti zen': 49,\n",
              " 'maruti zen estilo': 50,\n",
              " 'nissan kicks': 51,\n",
              " 'nissan terrano': 52,\n",
              " 'renault duster': 53,\n",
              " 'renault kwid': 54,\n",
              " 'skoda rapid': 55,\n",
              " 'tata hexa': 56,\n",
              " 'tata indigo': 57,\n",
              " 'tata neno': 58,\n",
              " 'tata nexon': 59,\n",
              " 'tata safari': 60,\n",
              " 'tata tiago': 61,\n",
              " 'tata zest': 62,\n",
              " 'toyota altis': 63,\n",
              " 'toyota etios': 64,\n",
              " 'toyota etios liva': 65,\n",
              " 'toyota fortuner': 66,\n",
              " 'toyota innova': 67,\n",
              " 'volkswagen ameo': 68,\n",
              " 'volkswagen polo': 69,\n",
              " 'volvo xc40': 70}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjvua5yFwbqX",
        "outputId": "64e27b0d-a6ae-4605-fcc9-87382d0b08f5"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/Colab Notebooks/Dataset/Test',\n",
        "                                            target_size = (224, 224),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 231 images belonging to 71 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTTkYBGWg1MS",
        "outputId": "1b504d61-c25c-4158-e8b5-7ef5b9b4c357"
      },
      "source": [
        "test_set.classes"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  2,  2,  3,  4,  5,  6,  7,  8,  9,  9,  9, 10, 11,\n",
              "       12, 12, 12, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 16, 17, 18,\n",
              "       19, 19, 19, 20, 20, 21, 21, 21, 21, 21, 21, 21, 22, 22, 23, 23, 23,\n",
              "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
              "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 25, 25,\n",
              "       25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 28, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 30, 31, 31, 31, 32, 33, 33, 33, 33, 34, 35, 35, 36,\n",
              "       36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 38, 38,\n",
              "       38, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 41, 41, 42, 42, 43, 44,\n",
              "       44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45,\n",
              "       45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
              "       46, 46, 46, 47, 48, 49, 50, 51, 52, 52, 53, 53, 53, 54, 55, 56, 57,\n",
              "       58, 59, 60, 61, 62, 63, 64, 64, 64, 64, 64, 64, 65, 65, 66, 66, 66,\n",
              "       67, 67, 67, 67, 67, 67, 67, 68, 69, 70], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeXPSjPhwbqY",
        "outputId": "fd404054-2ce5-47d3-c6a5-6e4340d23928"
      },
      "source": [
        "# fit the model\n",
        "# Run the cell. It will take some time to execute\n",
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=test_set,\n",
        "  epochs=50,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(test_set)\n",
        ")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "37/37 [==============================] - 387s 10s/step - loss: 13.3914 - accuracy: 0.0928 - val_loss: 15.8786 - val_accuracy: 0.1429\n",
            "Epoch 2/50\n",
            "37/37 [==============================] - 20s 543ms/step - loss: 14.3568 - accuracy: 0.1566 - val_loss: 15.7750 - val_accuracy: 0.1082\n",
            "Epoch 3/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 13.7418 - accuracy: 0.1891 - val_loss: 14.9753 - val_accuracy: 0.1991\n",
            "Epoch 4/50\n",
            "37/37 [==============================] - 20s 542ms/step - loss: 13.7800 - accuracy: 0.2073 - val_loss: 14.8628 - val_accuracy: 0.2554\n",
            "Epoch 5/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 13.6050 - accuracy: 0.2534 - val_loss: 14.9654 - val_accuracy: 0.1602\n",
            "Epoch 6/50\n",
            "37/37 [==============================] - 20s 543ms/step - loss: 13.1127 - accuracy: 0.2774 - val_loss: 14.8528 - val_accuracy: 0.2381\n",
            "Epoch 7/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 13.0954 - accuracy: 0.2668 - val_loss: 15.0488 - val_accuracy: 0.1818\n",
            "Epoch 8/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 13.6787 - accuracy: 0.2168 - val_loss: 15.0454 - val_accuracy: 0.1861\n",
            "Epoch 9/50\n",
            "37/37 [==============================] - 20s 544ms/step - loss: 13.4936 - accuracy: 0.2213 - val_loss: 14.8283 - val_accuracy: 0.2684\n",
            "Epoch 10/50\n",
            "37/37 [==============================] - 20s 553ms/step - loss: 14.0450 - accuracy: 0.2002 - val_loss: 15.1881 - val_accuracy: 0.1818\n",
            "Epoch 11/50\n",
            "37/37 [==============================] - 20s 543ms/step - loss: 13.5471 - accuracy: 0.2476 - val_loss: 15.0811 - val_accuracy: 0.1948\n",
            "Epoch 12/50\n",
            "37/37 [==============================] - 20s 545ms/step - loss: 13.3229 - accuracy: 0.2662 - val_loss: 15.0214 - val_accuracy: 0.1991\n",
            "Epoch 13/50\n",
            "37/37 [==============================] - 20s 544ms/step - loss: 13.1862 - accuracy: 0.2792 - val_loss: 14.8805 - val_accuracy: 0.2468\n",
            "Epoch 14/50\n",
            "37/37 [==============================] - 20s 545ms/step - loss: 13.7772 - accuracy: 0.2492 - val_loss: 14.9434 - val_accuracy: 0.2165\n",
            "Epoch 15/50\n",
            "37/37 [==============================] - 20s 542ms/step - loss: 13.5608 - accuracy: 0.2752 - val_loss: 14.9037 - val_accuracy: 0.2121\n",
            "Epoch 16/50\n",
            "37/37 [==============================] - 20s 547ms/step - loss: 13.0272 - accuracy: 0.2860 - val_loss: 14.8260 - val_accuracy: 0.2684\n",
            "Epoch 17/50\n",
            "37/37 [==============================] - 20s 545ms/step - loss: 13.6895 - accuracy: 0.2748 - val_loss: 14.9069 - val_accuracy: 0.2424\n",
            "Epoch 18/50\n",
            "37/37 [==============================] - 20s 544ms/step - loss: 13.3387 - accuracy: 0.2742 - val_loss: 14.9290 - val_accuracy: 0.2165\n",
            "Epoch 19/50\n",
            "37/37 [==============================] - 20s 542ms/step - loss: 13.6446 - accuracy: 0.2827 - val_loss: 14.8594 - val_accuracy: 0.2511\n",
            "Epoch 20/50\n",
            "37/37 [==============================] - 20s 547ms/step - loss: 13.3887 - accuracy: 0.2672 - val_loss: 15.2503 - val_accuracy: 0.1255\n",
            "Epoch 21/50\n",
            "37/37 [==============================] - 20s 544ms/step - loss: 13.7491 - accuracy: 0.2291 - val_loss: 15.0972 - val_accuracy: 0.1775\n",
            "Epoch 22/50\n",
            "37/37 [==============================] - 20s 544ms/step - loss: 12.7315 - accuracy: 0.3214 - val_loss: 14.8237 - val_accuracy: 0.2641\n",
            "Epoch 23/50\n",
            "37/37 [==============================] - 20s 542ms/step - loss: 13.3694 - accuracy: 0.2986 - val_loss: 14.8158 - val_accuracy: 0.2684\n",
            "Epoch 24/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 13.4651 - accuracy: 0.2997 - val_loss: 14.8524 - val_accuracy: 0.2554\n",
            "Epoch 25/50\n",
            "37/37 [==============================] - 20s 552ms/step - loss: 12.9126 - accuracy: 0.3140 - val_loss: 14.8363 - val_accuracy: 0.2468\n",
            "Epoch 26/50\n",
            "37/37 [==============================] - 20s 544ms/step - loss: 12.9593 - accuracy: 0.2949 - val_loss: 14.9973 - val_accuracy: 0.2165\n",
            "Epoch 27/50\n",
            "37/37 [==============================] - 20s 543ms/step - loss: 12.8905 - accuracy: 0.2960 - val_loss: 15.0616 - val_accuracy: 0.1905\n",
            "Epoch 28/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 13.3298 - accuracy: 0.2767 - val_loss: 15.0433 - val_accuracy: 0.2338\n",
            "Epoch 29/50\n",
            "37/37 [==============================] - 20s 543ms/step - loss: 13.8424 - accuracy: 0.2514 - val_loss: 14.8210 - val_accuracy: 0.2597\n",
            "Epoch 30/50\n",
            "37/37 [==============================] - 20s 545ms/step - loss: 13.3320 - accuracy: 0.2867 - val_loss: 14.9125 - val_accuracy: 0.2468\n",
            "Epoch 31/50\n",
            "37/37 [==============================] - 20s 547ms/step - loss: 13.0353 - accuracy: 0.2974 - val_loss: 14.8178 - val_accuracy: 0.2727\n",
            "Epoch 32/50\n",
            "37/37 [==============================] - 20s 544ms/step - loss: 12.9998 - accuracy: 0.3236 - val_loss: 14.8537 - val_accuracy: 0.2468\n",
            "Epoch 33/50\n",
            "37/37 [==============================] - 20s 543ms/step - loss: 13.5657 - accuracy: 0.2982 - val_loss: 14.8396 - val_accuracy: 0.2684\n",
            "Epoch 34/50\n",
            "37/37 [==============================] - 20s 547ms/step - loss: 13.3359 - accuracy: 0.3190 - val_loss: 14.8839 - val_accuracy: 0.2338\n",
            "Epoch 35/50\n",
            "37/37 [==============================] - 20s 544ms/step - loss: 12.9692 - accuracy: 0.3257 - val_loss: 14.8118 - val_accuracy: 0.2771\n",
            "Epoch 36/50\n",
            "37/37 [==============================] - 20s 539ms/step - loss: 12.9127 - accuracy: 0.3488 - val_loss: 14.8249 - val_accuracy: 0.2727\n",
            "Epoch 37/50\n",
            "37/37 [==============================] - 20s 538ms/step - loss: 13.9770 - accuracy: 0.2762 - val_loss: 14.9138 - val_accuracy: 0.2381\n",
            "Epoch 38/50\n",
            "37/37 [==============================] - 20s 542ms/step - loss: 13.5054 - accuracy: 0.2806 - val_loss: 14.8326 - val_accuracy: 0.2727\n",
            "Epoch 39/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 13.1844 - accuracy: 0.3286 - val_loss: 14.9218 - val_accuracy: 0.2294\n",
            "Epoch 40/50\n",
            "37/37 [==============================] - 20s 552ms/step - loss: 13.5391 - accuracy: 0.2768 - val_loss: 14.8328 - val_accuracy: 0.2641\n",
            "Epoch 41/50\n",
            "37/37 [==============================] - 20s 556ms/step - loss: 13.1760 - accuracy: 0.3284 - val_loss: 15.2644 - val_accuracy: 0.2121\n",
            "Epoch 42/50\n",
            "37/37 [==============================] - 20s 538ms/step - loss: 13.0295 - accuracy: 0.3051 - val_loss: 14.8208 - val_accuracy: 0.2554\n",
            "Epoch 43/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 13.0959 - accuracy: 0.3350 - val_loss: 14.8334 - val_accuracy: 0.2684\n",
            "Epoch 44/50\n",
            "37/37 [==============================] - 20s 541ms/step - loss: 13.2634 - accuracy: 0.3223 - val_loss: 14.9569 - val_accuracy: 0.2251\n",
            "Epoch 45/50\n",
            "37/37 [==============================] - 20s 543ms/step - loss: 13.6432 - accuracy: 0.2701 - val_loss: 14.9754 - val_accuracy: 0.2424\n",
            "Epoch 46/50\n",
            "37/37 [==============================] - 20s 555ms/step - loss: 13.3403 - accuracy: 0.3132 - val_loss: 14.8971 - val_accuracy: 0.2511\n",
            "Epoch 47/50\n",
            "37/37 [==============================] - 20s 534ms/step - loss: 12.7863 - accuracy: 0.3196 - val_loss: 14.8567 - val_accuracy: 0.2597\n",
            "Epoch 48/50\n",
            "37/37 [==============================] - 20s 532ms/step - loss: 13.1608 - accuracy: 0.2987 - val_loss: 14.9457 - val_accuracy: 0.2468\n",
            "Epoch 49/50\n",
            "37/37 [==============================] - 19s 524ms/step - loss: 12.8738 - accuracy: 0.3201 - val_loss: 14.9333 - val_accuracy: 0.2424\n",
            "Epoch 50/50\n",
            "37/37 [==============================] - 20s 539ms/step - loss: 13.4263 - accuracy: 0.2782 - val_loss: 14.8142 - val_accuracy: 0.2771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "xRGU42hiwbqY",
        "outputId": "2fce4039-75b1-407f-cbf4-d0580dadc7f6"
      },
      "source": [
        "# plot the loss\n",
        "plt.plot(r.history['loss'], label='train loss')\n",
        "plt.plot(r.history['val_loss'], label='val loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('LossVal_loss')\n",
        "\n",
        "# plot the accuracy\n",
        "plt.plot(r.history['accuracy'], label='train acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('AccVal_acc')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jIDKJ5jwbqZ"
      },
      "source": [
        "# save it as a h5 file\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('model_resnet50.h5')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_sgka6YwbqZ"
      },
      "source": [
        "y_pred = model.predict(test_set)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYJg-jSEwOQQ",
        "outputId": "3ec1f9a3-6296-4b67-969d-cc3d5e286290"
      },
      "source": [
        "y_pred.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(231, 71)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb248uddwV4z"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVWtH_40wY17",
        "outputId": "3c892244-4926-48e2-c77d-c04525003bec"
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23, 46, 44, 46, 46, 44, 44, 23, 46, 44, 14, 44, 46, 14, 14, 14, 44,\n",
              "       46, 23, 46, 46, 46, 14, 46, 23, 46, 44, 44, 23, 44, 23, 46, 44, 14,\n",
              "       46, 46, 44, 44, 14, 44, 14, 23, 23, 44, 46, 46, 23, 46, 14, 23, 14,\n",
              "       44, 44, 46, 14, 44, 44, 44, 14, 44, 44, 14, 14, 46, 46, 46, 46, 23,\n",
              "       23, 14, 46, 23, 44, 46, 44, 23, 23, 46, 14, 14, 46, 23, 23, 46, 23,\n",
              "       14, 44, 23, 46, 14, 44, 14, 14, 46, 46, 46, 14, 46, 44, 23, 23, 23,\n",
              "       44, 23, 14, 46, 23, 46, 46, 44, 23, 46, 14, 46, 46, 44, 23, 46, 14,\n",
              "       23, 44, 23, 46, 23, 46, 23, 23, 46, 23, 44, 46, 14, 46, 44, 14, 44,\n",
              "       23, 23, 14, 23, 46, 46, 23, 46, 46, 14, 46, 23, 44, 14, 14, 46, 23,\n",
              "       23, 46, 23, 46, 46, 46, 44, 14, 46, 23, 14, 23, 44, 23, 46, 46, 23,\n",
              "       44, 23, 46, 46, 44, 46, 14, 23, 46, 46, 23, 46, 23, 46, 46, 46, 14,\n",
              "       14, 44, 46, 23, 14, 14, 23, 46, 44, 46, 46, 46, 23, 14, 46, 23, 14,\n",
              "       46, 46, 46, 44, 46, 46, 46, 46, 23, 14, 44, 14, 46, 44, 46, 44, 44,\n",
              "       46, 44, 23, 44, 23, 44, 44, 46, 23, 23])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4G1EtqYigw6",
        "outputId": "46cdc4a5-bbb8-4fcb-9864-577fbd0321fc"
      },
      "source": [
        "y_true = test_set.classes\n",
        "y_true"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1,  1,  2,  2,  3,  4,  5,  6,  7,  8,  9,  9,  9, 10, 11,\n",
              "       12, 12, 12, 13, 13, 14, 14, 14, 14, 14, 14, 14, 15, 15, 16, 17, 18,\n",
              "       19, 19, 19, 20, 20, 21, 21, 21, 21, 21, 21, 21, 22, 22, 23, 23, 23,\n",
              "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
              "       23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 24, 24, 24, 24, 24, 25, 25,\n",
              "       25, 25, 25, 26, 26, 26, 26, 27, 27, 27, 28, 29, 29, 29, 29, 29, 29,\n",
              "       29, 29, 29, 29, 30, 31, 31, 31, 32, 33, 33, 33, 33, 34, 35, 35, 36,\n",
              "       36, 36, 36, 36, 36, 36, 36, 36, 36, 37, 37, 37, 37, 37, 37, 38, 38,\n",
              "       38, 38, 38, 38, 38, 39, 39, 39, 39, 40, 40, 41, 41, 42, 42, 43, 44,\n",
              "       44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 45, 45, 45, 45, 45, 45,\n",
              "       45, 45, 45, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
              "       46, 46, 46, 47, 48, 49, 50, 51, 52, 52, 53, 53, 53, 54, 55, 56, 57,\n",
              "       58, 59, 60, 61, 62, 63, 64, 64, 64, 64, 64, 64, 65, 65, 66, 66, 66,\n",
              "       67, 67, 67, 67, 67, 67, 67, 68, 69, 70], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfVM5R3JzRR9",
        "outputId": "75f8dc49-5b07-47ef-8c2b-26c642b84ace"
      },
      "source": [
        "np.unique(y_pred)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14, 23, 44, 46])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB5szRZYxEOM",
        "outputId": "f6147a64-e53b-413d-82c2-eeb5060e3848"
      },
      "source": [
        "# Labels (y_true)\n",
        "print(\"Name\\t\\t\\tIndex\")\n",
        "for key,val in dic_train.items():\n",
        "  print(\"{0:25}{1}\".format(key,val))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name\t\t\tIndex\n",
            "Mahindra Marazzo         0\n",
            "Maruti Ciaz              1\n",
            "Maruti Ertiga            2\n",
            "Tata Tigor               3\n",
            "audi a4                  4\n",
            "bmw 320                  5\n",
            "chevrolet Uva Sail       6\n",
            "chevrolet tavera         7\n",
            "force                    8\n",
            "ford ecosport            9\n",
            "ford fiesta              10\n",
            "ford figo                11\n",
            "honda amaze              12\n",
            "honda brv                13\n",
            "honda city               14\n",
            "honda city zx            15\n",
            "honda civic              16\n",
            "honda jazz               17\n",
            "honda mobilio            18\n",
            "honda wrv                19\n",
            "hyundai ACCENT           20\n",
            "hyundai creta            21\n",
            "hyundai eon              22\n",
            "hyundai i10              23\n",
            "hyundai i20              24\n",
            "hyundai santro           25\n",
            "hyundai verna            26\n",
            "hyundai xcent            27\n",
            "kia Carnival             28\n",
            "mahindra bolero          29\n",
            "mahindra imperio         30\n",
            "mahindra scorpio         31\n",
            "mahindra tuv300          32\n",
            "mahindra xuv500          33\n",
            "maruti 800               34\n",
            "maruti Celario           35\n",
            "maruti alto              36\n",
            "maruti baleno            37\n",
            "maruti brezza            38\n",
            "maruti eeco              39\n",
            "maruti ignis             40\n",
            "maruti omni              41\n",
            "maruti ritz              42\n",
            "maruti scross            43\n",
            "maruti swift             44\n",
            "maruti swift dzire       45\n",
            "maruti wagon r           46\n",
            "maruti xl6               47\n",
            "maruti xx4               48\n",
            "maruti zen               49\n",
            "maruti zen estilo        50\n",
            "nissan kicks             51\n",
            "nissan terrano           52\n",
            "renault duster           53\n",
            "renault kwid             54\n",
            "skoda rapid              55\n",
            "tata hexa                56\n",
            "tata indigo              57\n",
            "tata neno                58\n",
            "tata nexon               59\n",
            "tata safari              60\n",
            "tata tiago               61\n",
            "tata zest                62\n",
            "toyota altis             63\n",
            "toyota etios             64\n",
            "toyota etios liva        65\n",
            "toyota fortuner          66\n",
            "toyota innova            67\n",
            "volkswagen ameo          68\n",
            "volkswagen polo          69\n",
            "volvo xc40               70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjE9BKOqi_t6"
      },
      "source": [
        "### Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4GAxztQi92m",
        "outputId": "3ac240aa-3284-4e87-8672-782ab60dfe21"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heLrnNEMjwNe",
        "outputId": "ac613307-6d83-4fa1-f3a0-880168e64eff"
      },
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         1\n",
            "           1       0.00      0.00      0.00         3\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         1\n",
            "           6       0.00      0.00      0.00         1\n",
            "           7       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         1\n",
            "           9       0.00      0.00      0.00         3\n",
            "          10       0.00      0.00      0.00         1\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         3\n",
            "          13       0.00      0.00      0.00         2\n",
            "          14       0.02      0.14      0.04         7\n",
            "          15       0.00      0.00      0.00         2\n",
            "          16       0.00      0.00      0.00         1\n",
            "          17       0.00      0.00      0.00         1\n",
            "          18       0.00      0.00      0.00         1\n",
            "          19       0.00      0.00      0.00         3\n",
            "          20       0.00      0.00      0.00         2\n",
            "          21       0.00      0.00      0.00         7\n",
            "          22       0.00      0.00      0.00         2\n",
            "          23       0.11      0.20      0.14        30\n",
            "          24       0.00      0.00      0.00         5\n",
            "          25       0.00      0.00      0.00         5\n",
            "          26       0.00      0.00      0.00         4\n",
            "          27       0.00      0.00      0.00         3\n",
            "          28       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00        10\n",
            "          30       0.00      0.00      0.00         1\n",
            "          31       0.00      0.00      0.00         3\n",
            "          32       0.00      0.00      0.00         1\n",
            "          33       0.00      0.00      0.00         4\n",
            "          34       0.00      0.00      0.00         1\n",
            "          35       0.00      0.00      0.00         2\n",
            "          36       0.00      0.00      0.00        10\n",
            "          37       0.00      0.00      0.00         6\n",
            "          38       0.00      0.00      0.00         7\n",
            "          39       0.00      0.00      0.00         4\n",
            "          40       0.00      0.00      0.00         2\n",
            "          41       0.00      0.00      0.00         2\n",
            "          42       0.00      0.00      0.00         2\n",
            "          43       0.00      0.00      0.00         1\n",
            "          44       0.02      0.08      0.03        12\n",
            "          45       0.00      0.00      0.00         9\n",
            "          46       0.11      0.53      0.18        17\n",
            "          47       0.00      0.00      0.00         1\n",
            "          48       0.00      0.00      0.00         1\n",
            "          49       0.00      0.00      0.00         1\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         1\n",
            "          52       0.00      0.00      0.00         2\n",
            "          53       0.00      0.00      0.00         3\n",
            "          54       0.00      0.00      0.00         1\n",
            "          55       0.00      0.00      0.00         1\n",
            "          56       0.00      0.00      0.00         1\n",
            "          57       0.00      0.00      0.00         1\n",
            "          58       0.00      0.00      0.00         1\n",
            "          59       0.00      0.00      0.00         1\n",
            "          60       0.00      0.00      0.00         1\n",
            "          61       0.00      0.00      0.00         1\n",
            "          62       0.00      0.00      0.00         1\n",
            "          63       0.00      0.00      0.00         1\n",
            "          64       0.00      0.00      0.00         6\n",
            "          65       0.00      0.00      0.00         2\n",
            "          66       0.00      0.00      0.00         3\n",
            "          67       0.00      0.00      0.00         7\n",
            "          68       0.00      0.00      0.00         1\n",
            "          69       0.00      0.00      0.00         1\n",
            "          70       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.07       231\n",
            "   macro avg       0.00      0.01      0.01       231\n",
            "weighted avg       0.02      0.07      0.03       231\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh6DR4Id1BSi",
        "outputId": "2a1c4eb9-684d-4a74-d514-2ad83f4a6919"
      },
      "source": [
        "print(len(set(y_true) - set(y_pred)))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "67\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsKI71Bz1AOr"
      },
      "source": [
        "### Conclusion \n",
        "\n",
        "There are 67 classes which are not being predicted by the model.\n",
        "\n",
        "Loss function: Focal loss for multi class images\n",
        "\n",
        "Accuracy (final) = 7%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmEIVVJ-8--N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}